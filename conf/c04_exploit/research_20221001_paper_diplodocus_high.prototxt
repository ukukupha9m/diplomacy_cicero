# A training config for Diplodocus-High model

includes { path: "rollouters/bqre_20211212_rl_rollouts_bpr_sterm"; mount: "search_rollout.agent" }
includes { path: "opponents/searchbot_20210501_translite_rol0"; mount: "search_rollout.h2h_eval_0" }
includes { path: "opponents/base_strategy_model_20210501_heavyish"; mount: "search_rollout.h2h_eval_1" }
includes { path: "launcher/slurm_8gpus32gb_diplomacy.prototxt"; mount: "launcher" }
exploit {
    model_path: "models/nopress_human_imitation_for_rl_1.ckpt"
    value_model_path: "models/nopress_human_imitation_for_rl_1.ckpt"

    critic_weight: 1.0
    discounting: 1.0
    search_policy_weight: 0.1
    num_train_gpus: 4
    bootstrap_offline_targets: true
    use_distributed_data_parallel: true
    optimizer {
        adam {
            lr: 1e-4
        }
        warmup_epochs: 100
        grad_clip: 0.5
    }
    search_rollout {
        agent {
            bqre1p {
                player_types {
                    log_uniform {
                        min_lambda: 0.01
                        max_lambda: 0.1
                    }
                }
            }
        }
        extra_params {
            explore_eps: 0.1
            independent_explore: true
            use_ev_targets: true
            use_cfr_evs: true
            allow_policy_tragets_without_do: true
            use_trained_policy: 1
            run_do_prob: 0.1
        }
        chunk_length: 128
        batch_size: 8
        warmup_batches: 500
        num_workers_per_gpu: 8
        num_cores_to_reserve: 70
        draw_on_stalemate_years: 3
        enforce_train_gen_ratio: 6
        buffer {
            shuffle: 1
            prefetch: 5
            capacity: 10000
        }
        test_situation_eval {
            do_eval: false
        }
    }
    trainer {
        max_epochs: 3001
        epoch_size: 100
        save_checkpoint_every: 100
        save_sync_checkpoint_every: 40
    }
    launcher {
        slurm {
            num_gpus: 448
        }
    }
}